# Bach Harmonies: A Deep Learning Approach to Generating Chorale Music

## Project Overview

"Bach Harmonies" is a deep learning project designed to generate new music inspired by the chorales of Johann Sebastian Bach. Utilizing a dataset of 382 Bach chorales, this project employs sequence-to-sequence recurrent neural networks (RNNs) to predict musical chords and generate novel chorale sequences.

## Motivation

The motivation behind "Bach Harmonies" lies in the challenge of capturing the complexity and beauty of Bach's compositions through machine learning. This project aims not only to create music that maintains the stylistic elements of Bach's chorales but also to explore the potential of neural networks in understanding and replicating classical music composition techniques.

## Project Workflow

The development of "Bach Harmonies" can be broken down into the following key stages, providing a structured approach to generating new music based on Bach's chorales:

### 1. Data Acquisition and Preprocessing

- **Data Acquisition:** The project utilizes a dataset of 382 chorales by Johann Sebastian Bach. Each chorale is represented through chords, with each chord composed of four integers that indicate the notes played.
- **Preprocessing:** The chords are preprocessed to handle missing values and to convert them into a suitable format for training the neural network. This involves encoding the musical notes as integers and creating training sequences that the model can learn from.

### 2. Model Development

- **Architecture Design:** A sequence-to-sequence recurrent neural network (RNN) model is designed, employing Gated Recurrent Unit (GRU) layers for learning the temporal dependencies between chords. The use of embeddings helps in reducing the dimensionality of the input space and capturing the relationships between different chords.
- **Training:** The model is trained on the preprocessed dataset, learning to predict the next chord in a sequence given the previous chords. The training process involves adjusting the model's parameters to minimize the prediction error.

### 3. Music Generation

- **Chord Prediction:** Using the trained model, new sequences of chords are generated by feeding an initial chord or sequence into the model and using its predictions as the input for subsequent predictions.
- **Postprocessing:** The predicted sequences of chords are postprocessed to convert them back into a musical format, such as MIDI, allowing for playback and evaluation of the generated music.

### 4. Evaluation and Refinement

- **Evaluation:** The quality of the generated music is evaluated based on its similarity to Bach's style, coherence, and musicality. This qualitative assessment can involve both expert judgment and feedback from listeners.
- **Refinement:** Based on the evaluation, the model and its training process are refined to improve the quality of the generated music. This might include tuning hyperparameters, experimenting with different model architectures, and incorporating additional data.

### 5. Deployment and Sharing

- **Deployment:** The final model is made available for others to use, either through a web application or by sharing the model weights and generation scripts.
- **Sharing:** The project, along with its source code, documentation, and generated music samples, is shared with the community for feedback, collaboration, and further development.

This structured workflow ensures a systematic approach to the project, from the initial data handling to the final generation of new music, allowing for iterative improvements and innovation in the application of deep learning to music generation.

## Technical Details

### Technologies Used

- Python
- TensorFlow and Keras for deep learning
- Pandas and NumPy for data manipulation

### Dataset

The dataset comprises 382 chorales by Johann Sebastian Bach, with each chorale consisting of 100 to 640 chords. Each chord is represented by four integers corresponding to musical notes, facilitating the training of the neural network models.

### Model Architecture

The project uses a sequence-to-sequence RNN model with GRU layers and embeddings to predict the next chord in a sequence. The model's architecture is designed to handle the temporal nature of music, learning the patterns and dependencies between successive chords.

### Challenges and Learnings

One of the main challenges was dealing with the variable lengths of chorales and efficiently encoding musical information for the neural network. Through this project, significant insights were gained into sequence prediction problems, data preprocessing for deep learning, and the application of RNNs to creative domains like music generation.

## Getting Started

To replicate or build upon this project, you will need:

1. Python 3.x and pip
2. Dependencies: TensorFlow, Keras, Pandas, NumPy
3. The Bach chorales dataset (instructions for downloading and preprocessing are included in the notebook)

### Installation

Install the required Python libraries using:

```bash
pip install tensorflow keras pandas numpy
```

## Usage

The project is encapsulated in a Jupyter Notebook that walks through the dataset preparation, model training, and music generation process. To generate new music:

1. Train the model using the provided dataset.
2. Use the model to predict new chords and compile them into a chorale.
3. Convert the numerical chord representations back into music (MIDI or a similar format) for playback.

## Future Work

Future directions include exploring more complex models, such as Transformer networks, to capture deeper musical structures and experimenting with different representations of musical data to enhance the quality of generated compositions.

## License

This project is open-sourced under the MIT License.

## Acknowledgments

Special thanks to the creators of the TensorFlow and Keras libraries for providing the tools essential for this project's development, and to Johann Sebastian Bach, whose timeless compositions made this project possible.
